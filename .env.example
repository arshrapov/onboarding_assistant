# ============================================================
# Onboarding Assistant Environment Variables - EXAMPLE
# ============================================================
# Copy this file to .env and fill in your actual values

# ============================================================
# REQUIRED CONFIGURATION
# ============================================================

# Gemini API Key (REQUIRED)
# Get your key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# ============================================================
# OPTIONAL: GitHub Integration
# ============================================================

# GitHub Personal Access Token (for private repos or higher rate limits)
# Get from: https://github.com/settings/tokens
# Uncomment and set your token below:
GITHUB_TOKEN=ghp_your_token_here

# ============================================================
# DIRECTORY CONFIGURATION
# ============================================================

# Data directories (paths relative to project root)
DATA_DIR=./data
REPOS_DIR=./data/repos
INDEXES_DIR=./data/indexes
CACHE_DIR=./data/cache

# ============================================================
# LLM SETTINGS
# ============================================================

# Gemini model to use for text generation
# Options: "models/gemini-2.5-flash", "models/gemini-2.5-pro", "models/gemini-2.0-flash"
GEMINI_MODEL=models/gemini-2.5-flash

# LLM generation parameters
MAX_TOKENS=8192
TEMPERATURE=0.7

# ============================================================
# EMBEDDING SETTINGS (LlamaIndex with Gemini)
# ============================================================

# Gemini embedding model
EMBEDDING_MODEL=models/embedding-001

# ============================================================
# VECTOR DATABASE (ChromaDB)
# ============================================================

# ChromaDB mode: "embedded" (local) or "server" (remote)
CHROMA_MODE=embedded

# ChromaDB server settings (only used if CHROMA_MODE=server)
# CHROMA_HOST=localhost
# CHROMA_PORT=8000

# Collection name prefix for ChromaDB
CHROMA_COLLECTION_PREFIX=onboarding_

# ============================================================
# RAG CONFIGURATION
# ============================================================

# Number of top results to retrieve from vector search
TOP_K_RESULTS=10

# Code chunking settings (for fallback file parsing)
CHUNK_SIZE=3000
CHUNK_OVERLAP=400

# ============================================================
# SERVER SETTINGS
# ============================================================

# FastAPI server configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=7860

# ============================================================
# FILE PROCESSING
# ============================================================

# Maximum file size to process (in MB)
MAX_FILE_SIZE_MB=5

# Supported file extensions (comma-separated)
# Default: .py,.js,.ts,.tsx,.jsx,.java,.go,.rs,.cpp,.c,.h,.hpp,.cs,.rb,.php,.md,.txt,.json,.yaml,.yml
# SUPPORTED_EXTENSIONS=.py,.js,.ts,.md